{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un RAG en Local sur un ensemble de papier de recherche en Reinforcement Deep Learning \n",
    "\n",
    "OpenAI liste les principaux papiers du domaine sur cette page : https://spinningup.openai.com/en/latest/spinningup/keypapers.html\n",
    "On rajoutera aussi le livre de Sutton et al.: http://incompleteideas.net/book/RLbook2020.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Scrapping des pdf\n",
    "### Récupération des liens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liens trouvés:  ['https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf', 'https://arxiv.org/abs/1507.06527', 'https://arxiv.org/abs/1511.06581', 'https://arxiv.org/abs/1509.06461', 'https://arxiv.org/abs/1511.05952', 'https://arxiv.org/abs/1710.02298', 'https://arxiv.org/abs/1602.01783', 'https://arxiv.org/abs/1502.05477', 'https://arxiv.org/abs/1506.02438', 'https://arxiv.org/abs/1707.06347', 'https://arxiv.org/abs/1707.02286', 'https://arxiv.org/abs/1708.05144', 'https://arxiv.org/abs/1611.01224', 'https://arxiv.org/abs/1801.01290', 'http://proceedings.mlr.press/v32/silver14.pdf', 'https://arxiv.org/abs/1509.02971', 'https://arxiv.org/abs/1802.09477', 'https://arxiv.org/abs/1707.06887', 'https://arxiv.org/abs/1710.10044', 'https://arxiv.org/abs/1806.06923', 'https://openreview.net/forum?id=ByG_3s09KX', 'https://github.com/google/dopamine', 'https://arxiv.org/abs/1611.02247', 'https://arxiv.org/abs/1710.11198', 'https://arxiv.org/abs/1802.10031', 'https://arxiv.org/abs/1702.08892', 'https://arxiv.org/abs/1707.01891', 'https://arxiv.org/abs/1611.01626', 'https://arxiv.org/abs/1704.04651', 'http://papers.nips.cc/paper/6974-interpolated-policy-gradient-merging-on-policy-and-off-policy-gradient-estimation-for-deep-reinforcement-learning', 'https://arxiv.org/abs/1704.06440', 'https://arxiv.org/abs/1703.03864', 'https://arxiv.org/abs/1605.09674', 'https://arxiv.org/abs/1606.01868', 'https://arxiv.org/abs/1703.01310', 'https://arxiv.org/abs/1611.04717', 'https://arxiv.org/abs/1703.01260', 'https://arxiv.org/abs/1705.05363', 'https://arxiv.org/abs/1808.04355', 'https://arxiv.org/abs/1810.12894', 'https://arxiv.org/abs/1611.07507', 'https://arxiv.org/abs/1802.06070', 'https://arxiv.org/abs/1807.10299', 'https://arxiv.org/abs/1606.04671', 'http://proceedings.mlr.press/v37/schaul15.pdf', 'https://arxiv.org/abs/1611.05397', 'https://arxiv.org/abs/1707.03300', 'https://arxiv.org/abs/1701.08734', 'https://arxiv.org/abs/1707.07907', 'https://openreview.net/forum?id=rk07ZXZRb&noteId=rk07ZXZRb', 'https://arxiv.org/abs/1707.01495', 'https://arxiv.org/abs/1606.04695', 'https://arxiv.org/abs/1703.01161', 'https://arxiv.org/abs/1805.08296', 'https://arxiv.org/abs/1606.04460', 'https://arxiv.org/abs/1703.01988', 'https://arxiv.org/abs/1702.08360', 'https://arxiv.org/abs/1803.10760', 'https://arxiv.org/abs/1806.01822', 'https://arxiv.org/abs/1707.06203', 'https://arxiv.org/abs/1708.02596', 'https://arxiv.org/abs/1803.00101', 'https://arxiv.org/abs/1807.01675', 'https://openreview.net/forum?id=SJJinbWRZ&noteId=SJJinbWRZ', 'https://arxiv.org/abs/1809.05214', 'https://arxiv.org/abs/1809.01999', 'https://arxiv.org/abs/1712.01815', 'https://arxiv.org/abs/1705.08439', 'https://arxiv.org/abs/1611.02779', 'https://arxiv.org/abs/1611.05763', 'https://arxiv.org/abs/1703.03400', 'https://openreview.net/forum?id=B1DmUzWAW&noteId=B1DmUzWAW', 'https://arxiv.org/abs/1803.02811', 'https://arxiv.org/abs/1802.01561', 'https://openreview.net/forum?id=H1Dy---0Z', 'https://openreview.net/forum?id=r1lyTjAqYX', 'https://arxiv.org/abs/1712.09381', 'https://ray.readthedocs.io/en/latest/rllib.html', 'https://arxiv.org/abs/1809.07731', 'https://arxiv.org/abs/1808.00177', 'https://arxiv.org/abs/1806.10293', 'https://arxiv.org/abs/1811.00260', 'https://arxiv.org/abs/1606.06565', 'https://arxiv.org/abs/1706.03741', 'https://arxiv.org/abs/1705.10528', 'https://arxiv.org/abs/1801.08757', 'https://arxiv.org/abs/1707.05173', 'https://arxiv.org/abs/1711.06782', 'http://www.cs.cmu.edu/~bziebart/publications/thesis-bziebart.pdf', 'https://arxiv.org/abs/1603.00448', 'https://arxiv.org/abs/1606.03476', 'https://xbpeng.github.io/projects/DeepMimic/2018_TOG_DeepMimic.pdf', 'https://arxiv.org/abs/1810.00821', 'https://arxiv.org/abs/1810.05017', 'https://arxiv.org/abs/1604.06778', 'https://arxiv.org/abs/1708.04133', 'https://arxiv.org/abs/1709.06560', 'https://arxiv.org/abs/1810.02525', 'https://arxiv.org/abs/1811.02553', 'https://arxiv.org/abs/1803.07055', 'https://arxiv.org/abs/1907.02057', 'https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf', 'http://web.mit.edu/jnt/www/Papers/J063-97-bvr-td.pdf', 'http://www.kyb.mpg.de/fileadmin/user_upload/files/publications/attachments/Neural-Netw-2008-21-682_4867%5b0%5d.pdf', 'https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/KakadeLangford-icml2002.pdf', 'https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf', 'https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf']\n"
     ]
    }
   ],
   "source": [
    "# Récupération des liens des pdfs du site\n",
    "url = \"https://spinningup.openai.com/en/latest/spinningup/keypapers.html\"\n",
    "response = requests.get(url)\n",
    "\n",
    "pdf_links = []\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    links = [a['href'] for a in soup.find_all('a', class_='reference external') if 'href' in a.attrs]\n",
    "    print(\"liens trouvés: \", links)\n",
    "else:\n",
    "    print(\"Erreur lors du téléchargement de la page\")\n",
    "\n",
    "# scrapping dans arkiv et openreview\n",
    "for link in links:\n",
    "\n",
    "    if link.startswith(\"https://arxiv.org/\") or link.startswith(\"https://openreview\"):\n",
    "        a_class,pref = (\"abs-button download-pdf\",\"https://arxiv.org\") if link.startswith(\"https://arxiv.org/\") else (\"note_content_pdf\",\"https://openreview.net\")\n",
    "        r = requests.get(link)\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.text,'html.parser')\n",
    "            pdf_link = [a['href'] for a in soup.find_all('a', class_=a_class) if 'href' in a.attrs]\n",
    "            pdf_links.append(pref+pdf_link[0])\n",
    "        else:\n",
    "            print(\"problem\")\n",
    "\n",
    "    elif  link.endswith(\".pdf\"):\n",
    "        pdf_links.append(link)\n",
    "\n",
    "pdf_links.append(\"http://incompleteideas.net/book/RLbook2020.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement des pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m pdf_links \u001b[38;5;241m=\u001b[39m pdf_links\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (i,pdf_link) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpdf_links\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      7\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/papier_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"data/\"):\n",
    "    os.mkdir(\"data/\")\n",
    "\n",
    "pdf_links = pdf_links\n",
    "\n",
    "for (i,pdf_link) in tqdm(enumerate(pdf_links)):\n",
    "    path = \"data/papier_\"+str(i)+ \".pdf\"\n",
    "    \n",
    "    if not os.path.isfile(path):\n",
    "        pdf_r = requests.get(pdf_link)\n",
    "        if pdf_r.status_code == 200:\n",
    "            with open(path,\"wb\") as f:\n",
    "                f.write(pdf_r.content)\n",
    "        else:\n",
    "            print(\"probleme de téléchargement\")\n",
    "    else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "def text_to_sentences(text):\n",
    "    nlp = English()\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    doc = nlp(text)\n",
    "\n",
    "    sentences = [str(s) for s in list(doc.sents)]\n",
    "    return sentences\n",
    "\n",
    "def sentence_list_to_chunk(nb_sentence :  int,s_list : list[str]):\n",
    "    chunks = [\" \".join(s_list[i:i+nb_sentence]) for i in range(0,len(s_list),nb_sentence)]\n",
    "    return chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm as tqn\n",
    "\n",
    "data_path = \"data/\"\n",
    "pdf_files = [\"data/\"+f for f in os.listdir(data_path) if f.endswith('.pdf')]\n",
    "pdf_dic = {}\n",
    "\n",
    "def text_formatter(text:str) -> str:\n",
    "    cleaned_text = text.replace(\"\\n\",\" \").strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    pages_and_text = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for (page_number,page) in enumerate(doc):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text=text)\n",
    "        sentences = text_to_sentences(text)\n",
    "        chunks = sentence_list_to_chunk(10,sentences)\n",
    "        pages_and_text.append({\n",
    "            \"page_number\": page_number,\n",
    "            \"text\": text,\n",
    "            \"chunks\": chunks,\n",
    "            \"page_char_count\": len(text),\n",
    "            \"page_words_count\": len(text.split(\" \")),\n",
    "            \"page_sentences_count\": len(text.split(\". \")),\n",
    "            \"page_token_count\": len(text)/4,\n",
    "            \"page_chunks_count\": len(chunks)\n",
    "        })\n",
    "    return pages_and_text\n",
    "\n",
    "def open_pdfs(pdf_path_list : list[str]) -> list[dict]:\n",
    "    pdf_and_text = []\n",
    "    pdfs_pages_text_list = []\n",
    "    for (pdf_number,pdf_path) in tqn(enumerate(pdf_path_list),total=len(pdf_path_list)):\n",
    "\n",
    "        pages_and_text = open_and_read_pdf(pdf_path)\n",
    "        pdfs_pages_text_list.append(pages_and_text)\n",
    "        df = pd.DataFrame(pages_and_text)\n",
    "        dict_mean = df.describe().round(2).loc['mean'].to_dict()\n",
    "\n",
    "        doc = fitz.open(pdf_path)\n",
    "        texte_complet = \"\".join([page.get_text(\"text\") for page in doc])\n",
    "        texte_complet = text_formatter(texte_complet)\n",
    "        pdf_and_text.append({\n",
    "            \"pdf_number\":pdf_number,\n",
    "            \"pdf_page_count\":doc.page_count,\n",
    "            \"pdf_char_count\":len(texte_complet),\n",
    "            \"pdf_word_count\":len(texte_complet.split(\" \")),\n",
    "            \"pdf_sentence_count_raw\":len(texte_complet.split(\". \")),\n",
    "            \"pdf_token_count\": len(texte_complet) /4,\n",
    "            \"page_mean_char_count\": dict_mean[\"page_char_count\"],\n",
    "            \"page_mean_words_count\": dict_mean[\"page_words_count\"],\n",
    "            \"page_mean_sentences_count\": dict_mean[\"page_sentences_count\"],\n",
    "            \"page_mean_token_count\": dict_mean[\"page_token_count\"]\n",
    "        })\n",
    "    return pdf_and_text,pdfs_pages_text_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des chunks de phrases. \n",
    "On parcours les toutes les pages des pdfs. Pour chaque page, on prends tout le texte on le sépare en phrases qu'on met dans une liste, on crée ensuite une liste donc chaque élément est une liste de 10 phrases. On met ca dans un dictionnaire avec les données suivante: le nom du papier, le numéro de page absolue du papier, le lien du papier (local). On fait une liste du dictionnaire pour toutes les pages d'un papier. On rajoute dans cette liste tout les autres pdfs. Ca nous donne un gros dataframe avec un ensemble de listes de phrases. Apprès on prend ces chunks on les join et on crée u..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def pdfs_to_chunks(data_path):\n",
    "    pdf_files = [data_path+f for f in os.listdir(data_path) if f.endswith('.pdf')]\n",
    "    chunks = []\n",
    "    pdf_and_text,pdfs_pages_text_list = open_pdfs(pdf_files)\n",
    "    \n",
    "    for (pdf_num,pdf) in enumerate(pdfs_pages_text_list):\n",
    "        for page in pdf:\n",
    "            for chunk in page[\"chunks\"]:\n",
    "                chk = {}\n",
    "                chk[\"pdf_number\"] = pdf_num\n",
    "                chk[\"page_number\"] = page[\"page_number\"]\n",
    "                chk[\"text\"] = chunk\n",
    "                chk[\"chunk_count\"] = len(chk[\"text\"])\n",
    "                chk[\"chunk_token_count\"] = len(chk[\"text\"])/4\n",
    "\n",
    "                chunks.append(chk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath = \"data/text_chunks_and_embeddings.csv\"\n",
    "if not os.path.isfile(csvpath):\n",
    "        \n",
    "    chunks_list = pdfs_to_chunks(\"data/\")\n",
    "    df = pd.DataFrame(chunks_list)\n",
    "    df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_number</th>\n",
       "      <th>page_number</th>\n",
       "      <th>text</th>\n",
       "      <th>chunk_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>6</td>\n",
       "      <td>505</td>\n",
       "      <td>Bellemare, M. G., Dabney, W., Munos, R. (2017)...</td>\n",
       "      <td>516</td>\n",
       "      <td>129.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>6</td>\n",
       "      <td>522</td>\n",
       "      <td>References 501 Mendel, J. M., McLaren, R. W. (...</td>\n",
       "      <td>373</td>\n",
       "      <td>93.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>6] Dart: Dynamic animation and robotics toolki...</td>\n",
       "      <td>387</td>\n",
       "      <td>96.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>1. Human Oversight Phase (duration = 4.5 hours...</td>\n",
       "      <td>579</td>\n",
       "      <td>144.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5617</th>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>Note, to reduce the number of actors needed pe...</td>\n",
       "      <td>1119</td>\n",
       "      <td>279.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pdf_number  page_number  \\\n",
       "1658           6          505   \n",
       "1793           6          522   \n",
       "3996          45            8   \n",
       "6451          86            4   \n",
       "5617          73            4   \n",
       "\n",
       "                                                   text  chunk_count  \\\n",
       "1658  Bellemare, M. G., Dabney, W., Munos, R. (2017)...          516   \n",
       "1793  References 501 Mendel, J. M., McLaren, R. W. (...          373   \n",
       "3996  6] Dart: Dynamic animation and robotics toolki...          387   \n",
       "6451  1. Human Oversight Phase (duration = 4.5 hours...          579   \n",
       "5617  Note, to reduce the number of actors needed pe...         1119   \n",
       "\n",
       "      chunk_token_count  \n",
       "1658             129.00  \n",
       "1793              93.25  \n",
       "3996              96.75  \n",
       "6451             144.75  \n",
       "5617             279.75  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# df = pd.DataFrame(chunks_list)\n",
    "# df.describe().round(2)\n",
    "# df = df[ df[\"chunk_token_count\"] >= 20]\n",
    "# len(df)\n",
    "# df = df[df[\"chunk_token_count\"] <= 600]\n",
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\",device = \"cpu\")\n",
    "\n",
    "if not os.path.isfile(csvpath):\n",
    "    for chunk in tqn(chunks_list,total=len(chunks_list)):\n",
    "        embeding = model.encode(chunk[\"text\"])\n",
    "        chunk[\"embedding\"] = embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(chunks_list)\n",
    "# df.describe().round(2)\n",
    "# df = df[ df[\"chunk_token_count\"] >= 20]\n",
    "# len(df)\n",
    "# df = df[df[\"chunk_token_count\"] <= 600]\n",
    "# df.sample(5)\n",
    "\n",
    "# df.to_csv(csvpath,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "csv_to_chunks = pd.read_csv(csvpath)\n",
    "csv_to_chunks.head()\n",
    "csv_to_chunks[\"embedding\"] = csv_to_chunks[\"embedding\"].apply(lambda x: np.fromstring(x.strip('[]'),sep = \" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_number</th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7543.00</td>\n",
       "      <td>7543.00</td>\n",
       "      <td>7543.00</td>\n",
       "      <td>7543.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.93</td>\n",
       "      <td>76.01</td>\n",
       "      <td>979.08</td>\n",
       "      <td>244.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.11</td>\n",
       "      <td>141.88</td>\n",
       "      <td>512.26</td>\n",
       "      <td>128.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>535.00</td>\n",
       "      <td>133.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>973.00</td>\n",
       "      <td>243.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.00</td>\n",
       "      <td>50.50</td>\n",
       "      <td>1364.00</td>\n",
       "      <td>341.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>102.00</td>\n",
       "      <td>547.00</td>\n",
       "      <td>2399.00</td>\n",
       "      <td>599.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pdf_number  page_number  chunk_count  chunk_token_count\n",
       "count     7543.00      7543.00      7543.00            7543.00\n",
       "mean        44.93        76.01       979.08             244.77\n",
       "std         33.11       141.88       512.26             128.07\n",
       "min          0.00         0.00        80.00              20.00\n",
       "25%          6.00         5.00       535.00             133.75\n",
       "50%         43.00        10.00       973.00             243.25\n",
       "75%         77.00        50.50      1364.00             341.00\n",
       "max        102.00       547.00      2399.00             599.75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0194,  0.0533, -0.0432,  ...,  0.0508,  0.0025, -0.0156],\n",
       "        [ 0.0036,  0.0735, -0.0157,  ...,  0.0680,  0.0357, -0.0103],\n",
       "        [-0.0025,  0.0549, -0.0376,  ...,  0.0487,  0.0173,  0.0063],\n",
       "        ...,\n",
       "        [ 0.0225,  0.0068, -0.0008,  ...,  0.0619,  0.0459, -0.0025],\n",
       "        [-0.0409, -0.0417, -0.0394,  ...,  0.0116,  0.0503, -0.0091],\n",
       "        [-0.0090, -0.0296, -0.0588,  ..., -0.0040,  0.0070, -0.0092]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "csv_to_chunks_list_of_dict = csv_to_chunks.to_dict(orient=\"records\")\n",
    "embedings = torch.tensor(np.stack(csv_to_chunks[\"embedding\"].to_list(),axis=0),dtype=torch.float32)\n",
    "embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pdf_number': 6,\n",
       " 'page_number': 1,\n",
       " 'text': 'Adaptive Computation and Machine Learning Francis Bach, series editor A complete list of books published in the Adaptive Computation and Machine Learning series appears at the back of this book.',\n",
       " 'chunk_count': 194,\n",
       " 'chunk_token_count': 48.5,\n",
       " 'embedding': array([-1.01828668e-02,  1.02995662e-02, -6.62129596e-02, -3.35998344e-03,\n",
       "        -2.96776053e-02, -3.55895027e-04,  3.03983614e-02,  9.73482803e-03,\n",
       "         6.97616430e-04,  1.94171425e-02,  4.28065844e-02,  2.64051128e-02,\n",
       "        -1.09434798e-02,  3.73748802e-02, -9.43878479e-03, -4.01231162e-02,\n",
       "         1.82673577e-02,  2.11566910e-02, -8.99788272e-03, -1.79039370e-02,\n",
       "        -2.52534915e-02, -4.76417430e-02,  3.14446003e-03,  4.36046124e-02,\n",
       "         1.38526810e-02,  2.32962482e-02, -6.87500788e-03, -2.14416254e-02,\n",
       "        -1.26709277e-03,  2.57759206e-02,  5.89846959e-03, -1.12615451e-02,\n",
       "        -1.24668106e-02,  3.97212617e-02,  1.55406190e-06, -3.18033881e-02,\n",
       "        -7.70333922e-03, -7.71931186e-03,  2.80537754e-02, -4.51453682e-03,\n",
       "         7.70399570e-02,  3.95495668e-02,  5.92276501e-03, -8.98838602e-03,\n",
       "        -1.87848005e-02,  3.71970497e-02,  4.55099270e-02, -3.57047394e-02,\n",
       "         3.91934663e-02,  3.22002638e-03, -1.06549431e-02, -2.70042028e-02,\n",
       "         6.82668947e-03,  1.09599903e-02,  9.40368883e-03, -5.65834939e-02,\n",
       "         3.13403755e-02, -6.64363205e-02,  1.66899692e-02, -5.30027486e-02,\n",
       "        -2.40200572e-02,  3.98428552e-02, -1.68140940e-02, -2.52428628e-03,\n",
       "         5.58068007e-02, -1.29555129e-02,  3.18498462e-02, -5.84146474e-03,\n",
       "        -5.83450198e-02, -4.76331599e-02,  3.85818593e-02,  1.08027589e-02,\n",
       "         1.27294175e-02, -1.47682698e-02, -1.34255756e-02,  4.06275019e-02,\n",
       "        -5.96855907e-03, -3.54618356e-02, -3.82606536e-02, -1.73098408e-02,\n",
       "        -2.56203208e-02, -9.76732466e-03, -5.80946309e-03,  2.73955916e-03,\n",
       "        -6.76191645e-04,  8.55082348e-02, -3.16490345e-02, -1.31709501e-02,\n",
       "         3.26814130e-02,  2.29304247e-02,  1.73786916e-02, -8.27026926e-03,\n",
       "         2.45778039e-02,  4.48263325e-02, -1.56830586e-02, -8.20957532e-04,\n",
       "        -4.80881482e-02,  2.94082495e-03, -4.76886258e-02, -3.73391919e-02,\n",
       "         9.68998447e-02,  2.59078853e-03,  1.85321122e-02,  1.41152600e-02,\n",
       "         1.54785300e-02,  1.78191084e-02, -2.09409315e-02, -2.10422184e-02,\n",
       "        -2.22624224e-02,  6.03359453e-02, -2.09437590e-02,  2.06621084e-02,\n",
       "        -1.39907250e-04,  6.38946220e-02,  3.71968001e-02,  4.81465347e-02,\n",
       "        -6.15350828e-02,  2.82089729e-02, -1.98512059e-02, -4.80860844e-02,\n",
       "        -6.33131433e-03, -2.67025959e-02, -2.95611424e-03,  2.61641089e-02,\n",
       "        -5.57359271e-02, -7.27498019e-03, -1.99527983e-02,  1.35028930e-02,\n",
       "        -3.36328484e-02,  2.26410571e-02,  3.65325958e-02, -2.86755543e-02,\n",
       "        -9.74273123e-03,  1.03125246e-02, -1.11767999e-03,  1.87529977e-02,\n",
       "         2.13431995e-02,  5.99097759e-02, -5.16588762e-02,  1.75450519e-02,\n",
       "         6.10868912e-03, -1.06800012e-02, -4.99853585e-03, -1.38876792e-02,\n",
       "         2.58493740e-02, -3.59476879e-02, -1.63772199e-02, -1.66516547e-04,\n",
       "        -3.07168476e-02, -8.18510074e-03, -4.88426648e-02,  3.80412713e-02,\n",
       "        -2.47759912e-02,  5.70241269e-03,  6.97337687e-02, -4.31206636e-02,\n",
       "        -2.72724330e-02,  3.61316390e-02,  5.81977936e-03, -1.94003433e-02,\n",
       "         2.83809006e-02, -2.80040819e-02,  5.65146562e-03,  2.68257055e-02,\n",
       "        -9.86321457e-03, -4.13928032e-02, -4.32058834e-02, -5.41446656e-02,\n",
       "        -1.03566963e-02,  1.81678347e-02, -5.53778186e-02,  1.95000153e-02,\n",
       "        -7.89109152e-03, -2.51818523e-02,  5.33374138e-02,  3.70192677e-02,\n",
       "         2.73603834e-02,  8.45078602e-02,  3.70035432e-02,  8.22661072e-03,\n",
       "         1.18964994e-02,  1.73336621e-02,  7.90248998e-03,  3.09678596e-02,\n",
       "        -1.04759298e-01, -5.11449538e-02, -1.87202655e-02,  1.12097114e-02,\n",
       "        -9.05976817e-03, -5.81413992e-02,  1.68767590e-02,  1.07545964e-02,\n",
       "        -2.35272646e-02, -2.53642742e-02,  6.51181862e-02, -2.07183547e-02,\n",
       "        -1.73525028e-02, -9.09154266e-02,  3.11811157e-02,  8.19125120e-03,\n",
       "        -2.88984179e-02, -8.25609863e-02,  2.09082533e-02,  6.04760693e-03,\n",
       "         2.74202935e-02, -8.13818648e-02, -1.61402076e-02,  7.27135129e-03,\n",
       "        -2.11642943e-02, -3.69248092e-02,  2.64988709e-02,  2.17515118e-02,\n",
       "         1.15801832e-02,  2.00145263e-02, -1.30702518e-02,  9.18438956e-02,\n",
       "        -6.82158116e-03, -5.14941989e-03, -5.34795001e-02, -1.91917848e-02,\n",
       "        -3.58138680e-02,  3.85533348e-02, -4.32706997e-02,  1.69966556e-02,\n",
       "         6.32165372e-03, -7.76798138e-03,  7.60742053e-02, -3.67351435e-03,\n",
       "         7.49415755e-02,  2.11018510e-02, -2.64824345e-03, -1.15163764e-02,\n",
       "         2.67428793e-02,  2.03410164e-02, -4.73504961e-02,  9.80686583e-03,\n",
       "         1.28390538e-02,  2.19335910e-02,  6.69115409e-02, -3.05080898e-02,\n",
       "         4.23331819e-02, -1.94597729e-02,  1.37702475e-04, -3.99315208e-02,\n",
       "         6.17183745e-02, -7.48200789e-02,  3.93398618e-03, -2.55855024e-02,\n",
       "         2.10974216e-02, -2.32270602e-02,  2.33096420e-04,  2.13112514e-02,\n",
       "         4.96185943e-02,  1.02237146e-02,  1.07338028e-02, -2.13921163e-02,\n",
       "        -5.31224906e-02, -1.09365601e-02, -5.33107156e-03, -6.25868468e-03,\n",
       "        -2.54044048e-02, -4.94986624e-02,  1.61813311e-02,  3.44656184e-02,\n",
       "         4.93206177e-03,  3.94865312e-02,  3.06576490e-02,  1.30016282e-02,\n",
       "        -4.60420549e-02,  6.33582007e-03,  2.65819789e-03, -2.00563502e-02,\n",
       "        -5.01057468e-02,  5.12541309e-02,  1.03403460e-02,  1.05202030e-02,\n",
       "         1.10902376e-01, -5.02786133e-03, -7.20651001e-02,  5.58624091e-03,\n",
       "        -6.76905178e-03, -3.13346200e-02,  3.58413765e-03, -3.31082046e-02,\n",
       "        -1.92261841e-02,  6.70390129e-02,  6.16783127e-02, -2.44078413e-02,\n",
       "        -5.53567410e-02, -3.00657228e-02, -8.03052727e-03,  3.68715525e-02,\n",
       "         1.59525294e-02, -2.44252179e-02, -5.56157716e-02, -2.75445804e-02,\n",
       "        -3.70744988e-02,  6.96764588e-02, -1.32784126e-02,  3.17512602e-02,\n",
       "         8.84099957e-03,  7.66819268e-02,  2.94213500e-02,  1.30774444e-02,\n",
       "        -3.92060988e-02, -4.25121747e-02,  8.16527754e-03, -1.59290247e-02,\n",
       "         3.86857539e-02,  9.96511709e-03,  5.90352900e-03,  1.11724697e-02,\n",
       "        -1.61929487e-03,  4.36408892e-02,  3.25953700e-02, -4.50548530e-02,\n",
       "        -3.80208343e-02, -1.62436906e-02, -3.44845536e-03,  3.41120772e-02,\n",
       "        -2.33817543e-03,  7.32609769e-03,  7.83842430e-02,  4.18226980e-02,\n",
       "         4.26023863e-02, -1.34467511e-02, -3.81215401e-02,  3.69742066e-02,\n",
       "        -7.00484589e-02,  1.66296102e-02,  2.30327267e-02, -4.87540616e-03,\n",
       "         3.55448723e-02,  4.97391867e-03, -1.57692935e-02,  2.36336086e-02,\n",
       "        -2.86379438e-02, -2.60421634e-02, -1.85492728e-02,  1.50635070e-03,\n",
       "         3.53123173e-02, -5.73780611e-02,  1.14918007e-02, -1.81737300e-02,\n",
       "         3.14175375e-02,  1.48708688e-03,  7.81975780e-03,  7.50203198e-03,\n",
       "        -6.79982901e-02,  2.19045766e-02,  1.71975382e-02,  5.52188717e-02,\n",
       "        -2.66347192e-02, -3.77238952e-02,  1.95520627e-03,  1.88802425e-02,\n",
       "        -3.24967429e-02,  4.98776399e-02, -2.18506660e-02, -3.72178257e-02,\n",
       "         1.97531730e-02,  1.00914277e-02,  6.31047860e-02, -1.58916954e-02,\n",
       "        -3.89227942e-02,  4.23993692e-02,  5.10660931e-02, -4.84219640e-02,\n",
       "        -3.05363629e-03,  5.32328896e-02, -2.34301481e-02, -7.51062529e-03,\n",
       "        -1.90150999e-02,  2.23367270e-02,  1.75057370e-02, -9.08196643e-02,\n",
       "        -2.57222224e-02, -3.32876630e-02, -8.87912326e-03, -2.60032271e-03,\n",
       "         3.93270180e-02, -2.11183783e-02,  1.39431870e-02, -1.82880946e-02,\n",
       "         5.60732372e-02, -4.04545590e-02, -4.97457683e-02,  3.62127647e-02,\n",
       "        -5.06052859e-02,  3.02382074e-02,  2.25272756e-02, -9.51025262e-02,\n",
       "        -3.78976390e-02, -3.79742831e-02, -1.44445859e-02, -6.62520900e-02,\n",
       "        -3.53479870e-02,  2.44745482e-02,  7.04180310e-03, -2.33317241e-02,\n",
       "         3.47853787e-02, -6.09986931e-02,  1.89885050e-02, -4.43353094e-02,\n",
       "        -3.50369364e-02,  5.67809120e-03,  4.27498072e-02,  3.26400548e-02,\n",
       "        -4.17321548e-02, -1.17190825e-02, -1.71003286e-02, -1.51811577e-02,\n",
       "         4.61284369e-02, -4.18322869e-02, -4.64671728e-04,  1.75417624e-02,\n",
       "         1.31009622e-02, -1.18527915e-02,  2.90414672e-02,  1.45411920e-02,\n",
       "         2.64473986e-02,  7.47634470e-02,  9.53834951e-02, -2.09901780e-02,\n",
       "         1.59092657e-02, -4.07193489e-02,  3.36539634e-02,  1.88922696e-02,\n",
       "        -1.33851338e-02,  1.33227902e-02, -7.96413571e-02, -2.62902267e-02,\n",
       "        -2.83313133e-02,  1.90689862e-02, -4.72962633e-02, -8.88866559e-03,\n",
       "         1.18283341e-02, -4.04497050e-02, -4.53506932e-02, -4.44638319e-02,\n",
       "         3.59957814e-02, -2.19963603e-02,  7.23202080e-02,  4.62011136e-02,\n",
       "        -1.88899059e-02,  6.56262040e-02,  2.43181176e-02, -5.46127744e-02,\n",
       "        -9.39946920e-02,  3.35490815e-02, -1.27087105e-02, -1.46033922e-02,\n",
       "         2.35752333e-02,  4.41915309e-03, -7.55480826e-02, -2.36620698e-02,\n",
       "        -3.22411880e-02, -1.10861426e-02, -2.56182402e-02,  7.95977563e-02,\n",
       "         9.38295871e-02,  3.15632895e-02,  1.71911791e-02, -4.91435118e-02,\n",
       "        -8.70489776e-02, -7.22210389e-04, -4.75342944e-03,  9.17305704e-03,\n",
       "         3.44420262e-02,  2.48150565e-02,  6.39815256e-03, -9.85623244e-03,\n",
       "         1.34870354e-02, -1.21917957e-02,  4.95067574e-02,  9.30705760e-03,\n",
       "        -3.16842012e-02,  1.54129136e-02, -6.62109628e-02,  1.30812423e-02,\n",
       "         2.40561645e-02,  5.36564458e-03,  9.33533348e-03, -7.20118284e-02,\n",
       "         8.84013809e-03,  3.26861255e-02,  8.14777315e-02,  2.94336933e-03,\n",
       "        -1.33363046e-02, -6.02342142e-03,  1.32165942e-02,  3.97474356e-02,\n",
       "        -1.62135214e-02, -7.93654695e-02,  1.99234504e-02, -4.48349342e-02,\n",
       "        -7.52952099e-02,  2.46786629e-03,  2.28079073e-02,  4.35775705e-02,\n",
       "        -5.46750948e-02,  1.84526294e-02,  1.95163004e-02,  2.07986422e-02,\n",
       "         4.20575626e-02,  2.01065484e-02, -1.64437909e-02,  5.75813130e-02,\n",
       "        -4.14341735e-03,  4.32946719e-02, -6.31184801e-02, -3.73237357e-02,\n",
       "        -6.35657683e-02,  1.25693092e-02, -3.29989083e-02,  3.98892350e-02,\n",
       "         3.19443271e-02,  3.97103690e-02, -2.41190381e-02, -2.48443615e-02,\n",
       "        -4.83170990e-03, -3.48370709e-02,  1.73642244e-02, -6.46463409e-03,\n",
       "         5.23543134e-02,  6.60974183e-04,  9.02906246e-03, -1.50722666e-02,\n",
       "         4.26348532e-03, -9.75312013e-03, -2.36896519e-02, -3.27766873e-02,\n",
       "        -5.57754328e-03, -2.58093588e-02, -3.70183922e-02,  5.81887504e-03,\n",
       "        -9.78921447e-03,  1.69291487e-03,  2.25590356e-02,  1.52005972e-02,\n",
       "        -3.54353674e-02, -3.56948376e-03,  3.00399885e-02,  1.21762324e-02,\n",
       "         7.47187510e-02, -1.01136848e-01,  1.52096469e-02,  3.67712043e-02,\n",
       "        -7.90316984e-03,  5.26222624e-02,  1.22359060e-02,  3.76831880e-03,\n",
       "        -5.43651134e-02,  2.39544176e-02,  3.60138454e-02, -5.46758238e-33,\n",
       "        -3.43286470e-02, -2.88824774e-02, -3.99853624e-02,  2.99867764e-02,\n",
       "        -1.41031463e-02, -2.45095510e-02,  3.99490334e-02, -3.61532830e-02,\n",
       "         2.59717386e-02, -3.68975736e-02, -3.22065577e-02,  9.88862570e-03,\n",
       "         1.95084773e-02, -3.18205245e-02,  1.90470535e-02,  3.64867412e-02,\n",
       "         1.77737214e-02, -3.25535461e-02, -3.85639723e-03, -4.16679820e-03,\n",
       "        -2.09717010e-03,  2.30967309e-02,  2.03045993e-03, -4.73769419e-02,\n",
       "        -3.80360223e-02,  3.57324183e-02, -5.21910097e-03,  4.34103468e-03,\n",
       "        -1.48816267e-02,  1.72647350e-02, -3.67367931e-04,  1.65916309e-02,\n",
       "        -5.54801524e-03, -4.45837388e-03,  2.90233232e-02, -2.85112038e-02,\n",
       "        -6.17219917e-02, -5.55910915e-03, -1.70274600e-02,  1.06351729e-02,\n",
       "        -8.99268256e-04, -2.45543998e-02,  1.01236522e-01,  1.74358319e-02,\n",
       "        -1.24845870e-01,  4.38354211e-03,  5.71431071e-02, -1.70284640e-02,\n",
       "        -4.73266207e-02, -3.24897319e-02, -3.21158133e-02,  1.07948855e-02,\n",
       "        -2.44916342e-02,  5.67079894e-02,  8.15344974e-03,  2.25912388e-02,\n",
       "        -4.54355516e-02, -2.87807137e-02,  1.95218006e-03,  6.21985495e-02,\n",
       "         5.02510034e-02,  3.89566422e-02, -1.53689431e-02, -3.51568428e-03,\n",
       "         2.93127983e-03,  7.23548606e-03,  1.26307115e-01, -1.11388918e-02,\n",
       "         2.64177769e-02, -3.45100611e-02, -1.64049100e-02,  6.42366149e-03,\n",
       "         6.99699149e-02,  1.65791772e-02,  1.13799134e-02, -3.74083407e-02,\n",
       "        -3.83161977e-02,  4.71232533e-02,  1.07549854e-01, -2.32780110e-02,\n",
       "         1.35324607e-02, -3.50229666e-02, -2.65767123e-03, -1.18235731e-02,\n",
       "         5.52028418e-02, -2.98588350e-02, -2.97475662e-02,  1.62437744e-02,\n",
       "        -2.49174088e-02, -3.23425122e-02, -5.84448921e-03,  2.57717501e-02,\n",
       "        -1.67579707e-02, -3.26059684e-02,  8.68397653e-02, -5.46343997e-02,\n",
       "         2.64996588e-02,  9.47152264e-03,  5.07329218e-02,  1.06233330e-02,\n",
       "         7.54613755e-03, -5.02320230e-02, -2.22926084e-02,  1.95976868e-02,\n",
       "         2.43802369e-02, -4.47983034e-02, -2.57337410e-02,  5.02310693e-02,\n",
       "        -2.64913253e-02,  8.40000622e-03,  5.79682784e-03, -1.98140182e-02,\n",
       "         4.13407711e-03,  2.95877364e-02,  4.84581925e-02, -1.24470983e-02,\n",
       "         1.41696138e-02,  7.30720814e-03, -4.41787671e-03, -6.42005354e-02,\n",
       "         8.12361017e-03,  1.63069170e-03,  2.06838828e-02,  2.71205120e-02,\n",
       "        -4.00045402e-02,  3.90730985e-03,  9.22000688e-03, -1.95596013e-02,\n",
       "        -6.95940182e-02, -7.39266351e-02, -3.87168191e-02,  1.45892352e-02,\n",
       "         2.21341779e-07, -5.56443818e-03,  6.05791025e-02, -5.39829116e-03,\n",
       "        -6.49507046e-02,  4.85387854e-02, -1.42867947e-02, -5.36286160e-02,\n",
       "         1.25836479e-02,  8.54039378e-03,  8.01741332e-02,  9.25663188e-02,\n",
       "        -5.39469495e-02,  2.98357252e-02, -2.17545424e-02,  1.27643812e-02,\n",
       "        -9.57962647e-02, -3.89829613e-02,  7.19581619e-02, -1.48268873e-02,\n",
       "         4.95704189e-02,  2.01764815e-02,  1.63399074e-02,  1.09583065e-02,\n",
       "        -1.13110235e-02,  1.33552747e-02, -2.26187911e-02, -1.01865409e-02,\n",
       "         6.13674754e-03,  3.25957127e-02, -4.37280759e-02,  2.43098512e-02,\n",
       "        -3.27969389e-03, -3.10697574e-02, -1.96073428e-02,  4.33339475e-04,\n",
       "         8.48223716e-02,  1.99489463e-02,  5.31769730e-02, -9.71562974e-03,\n",
       "         2.41553951e-02,  6.71123639e-02,  6.37575313e-02,  4.48888987e-02,\n",
       "        -8.19514971e-03,  2.84550488e-02, -2.80920807e-02, -2.00120844e-02,\n",
       "         2.69510522e-02, -4.27930132e-02, -1.77494138e-02,  8.32419551e-04,\n",
       "        -5.87492343e-03,  1.16882119e-02,  1.03584258e-02, -2.20304783e-02,\n",
       "         4.51414642e-04, -1.24984970e-02,  1.67453382e-02,  3.65291424e-02,\n",
       "         6.95322677e-02, -1.56227453e-02, -4.46333364e-02, -7.64245912e-03,\n",
       "         3.48434970e-02,  6.51648492e-02, -7.27000162e-02,  1.43749965e-02,\n",
       "         1.58746747e-34,  2.78461259e-02, -1.95578001e-02,  1.47979883e-02,\n",
       "         5.33745857e-03, -4.24556434e-02,  8.31420440e-03, -1.70544826e-03,\n",
       "         2.24612150e-02,  2.68810950e-02, -1.41026676e-02, -2.41542496e-02])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_to_chunks_list_of_dict[395]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Ca a mis 0.00837 pour faire le dot product sur 7543 embedings sur cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "query = \"What is Q learning\"\n",
    "query_embeding = model.encode(query,convert_to_tensor=True)\n",
    "\n",
    "\n",
    "from time import perf_counter as timer\n",
    "\n",
    "from sentence_transformers import util\n",
    "\n",
    "st = timer()\n",
    "dot_scores = model.similarity(a=query_embeding,b=embedings)\n",
    "et = timer()\n",
    "\n",
    "print(f\"[INFO] Ca a mis {et-st:.5f} pour faire le dot product sur {len(embedings)} embedings sur cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7080, 0.7076, 0.7052, 0.7008, 0.6953])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_k = torch.topk(dot_scores,k=5)\n",
    "csv_to_chunks_list_of_dict[31]\n",
    "tp_k.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def query_to_topk_chunks(query,chunks_text_dict_list,embedings,model,print_info:bool = True):\n",
    "    query_embeding = model.encode(query)\n",
    "    st = timer()\n",
    "    similarity = model.similarity(query_embeding,embedings)\n",
    "    ft = timer()\n",
    "\n",
    "    if print_info:\n",
    "        print(f\"Le temps pour calculer {len(embedings)} est de {ft-st:.5f}\")\n",
    "\n",
    "    topk = torch.topk(similarity,k=5)\n",
    "    context = []\n",
    "    for (i,indice) in enumerate(topk.indices[0]):\n",
    "        chunk = {\n",
    "            \"score\": topk.values[0][i],\n",
    "            \"text\": chunks_text_dict_list[indice][\"text\"],\n",
    "            \"pdf_number\": chunks_text_dict_list[indice][\"pdf_number\"],\n",
    "            \"page_number\": chunks_text_dict_list[indice][\"page_number\"]\n",
    "        }\n",
    "        context.append(chunk)\n",
    "    \n",
    "    return context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps pour calculer 7543 est de 0.00879\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "      <th>pdf_number</th>\n",
       "      <th>page_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(0.7080)</td>\n",
       "      <td>440 Chapter 16: Applications and Case Studies ...</td>\n",
       "      <td>6</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(0.7076)</td>\n",
       "      <td>Double q-learning. In Advances in Neural Infor...</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(0.7052)</td>\n",
       "      <td>Algorithm 12 The function implementing the tab...</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(0.7008)</td>\n",
       "      <td>Algorithm 13 The function implementing the Q-l...</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(0.6953)</td>\n",
       "      <td>the loss of information than does DQN. Thus, r...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score                                               text  \\\n",
       "0  tensor(0.7080)  440 Chapter 16: Applications and Case Studies ...   \n",
       "1  tensor(0.7076)  Double q-learning. In Advances in Neural Infor...   \n",
       "2  tensor(0.7052)  Algorithm 12 The function implementing the tab...   \n",
       "3  tensor(0.7008)  Algorithm 13 The function implementing the Q-l...   \n",
       "4  tensor(0.6953)  the loss of information than does DQN. Thus, r...   \n",
       "\n",
       "   pdf_number  page_number  \n",
       "0           6          461  \n",
       "1          18            9  \n",
       "2           5           56  \n",
       "3           5           58  \n",
       "4           1            1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = query_to_topk_chunks(query,csv_to_chunks_list_of_dict,embedings,model)\n",
    "contexte_df = pd.DataFrame(context)\n",
    "contexte_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
